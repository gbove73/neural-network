# Rete neurale "hand-made" per valutazione immobiliare

[![Java Version](https://img.shields.io/badge/Java-21%2B-blue.svg)](https://www.oracle.com/java/technologies/javase-jdk21-downloads.html)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Build](https://img.shields.io/badge/Build-Maven-red.svg)](https://maven.apache.org/)

## üìã Descrizione del progetto

Questo repository contiene un progetto **puramente dimostrativo** di una rete neurale implementata completamente a mano in Java, senza utilizzare framework o librerie di machine learning. L'obiettivo principale √® didattico: mostrare i fondamenti dell'implementazione di una rete neurale partendo dai primi principi matematici.

La rete neurale √® stata applicata al caso d'uso della valutazione immobiliare come esempio pratico, ma il focus √® sulla comprensione dell'algoritmo di backpropagation e del funzionamento interno delle reti neurali artificiali.

## üß† Perch√© una rete neurale scritta a mano?

Mentre esistono numerose librerie mature per il machine learning come TensorFlow, PyTorch o DeepLearning4J, questo progetto evita deliberatamente di utilizzarle per:

- **Scopo didattico** - Comprendere pienamente il funzionamento interno delle reti neurali
- **Trasparenza algortimica** - Visualizzare esattamente cosa accade durante l'addestramento e l'inferenza
- **Controllo completo** - Implementare ogni aspetto dell'algoritmo senza astrazioni
- **Semplicit√†** - Mantenere il codice leggibile e comprensibile senza dipendenze complesse

## üèóÔ∏è Architettura della rete neurale

La rete implementata √® un percettrone multistrato con:

- **Input Layer** - 5 neuroni rappresentanti le caratteristiche immobiliari
- **Hidden Layer** - Singolo strato nascosto configurabile (default: 8 neuroni)
- **Output Layer** - Singolo neurone che produce la stima del prezzo
- **Funzione di attivazione** - Sigmoide per l'introduzione di non-linearit√†
- **Addestramento** - Backpropagation con discesa stocastica del gradiente
- **Regolarizzazione** - Implementazione del dropout per prevenire l'overfitting

## üöÄ Installazione

```bash
# Clona il repository
git clone git@github.com:gbove73/neural-network.git

# Entra nella directory del progetto
cd neural-network

# Compila il progetto con Maven
mvn clean install
```

## üíª Esempio di Utilizzo

```java
// Crea una rete neurale con la configurazione predefinita
RealEstateNeuralNetwork evaluator = new RealEstateNeuralNetwork();

// Definisce un semplice dataset di addestramento
double[][] properties = {
    {80.0, 3.0, 1.0, 2.0, 7.0},   // 220.000‚Ç¨ - appartamento medio in buona zona
    {150.0, 4.0, 2.0, 3.0, 8.0},  // 380.000‚Ç¨ - appartamento grande in ottima zona
    {50.0, 2.0, 1.0, 1.0, 5.0}    // 150.000‚Ç¨ - appartamento piccolo in zona media
};
double[] prices = {220000.0, 380000.0, 150000.0};

// Addestra il modello per 5000 epoche
evaluator.train(properties, prices, 5000);

// Stima il prezzo di un nuovo immobile
double price = evaluator.estimatePrice(100.0, 3, 1, 2, 6);
System.out.println("Prezzo stimato: ‚Ç¨" + (int)price);
```

## üìö Struttura del progetto

### üèõÔ∏è Organizzazione dei package

Il progetto √® strutturato seguendo i principi di Clean Architecture, che garantisce separazione delle responsabilit√† e indipendenza dai framework:

```
it.bove
‚îú‚îÄ‚îÄ core                 // Logica di business centrale indipendente dal dominio
‚îÇ   ‚îú‚îÄ‚îÄ nn               // Implementazione base rete neurale
‚îÇ   ‚îî‚îÄ‚îÄ normalization    // Normalizzazione dati generica
‚îú‚îÄ‚îÄ domain               // Regole di business specifiche del dominio
‚îÇ   ‚îî‚îÄ‚îÄ realestate       // Dominio della valutazione immobiliare
‚îú‚îÄ‚îÄ application          // Casi d'uso dell'applicazione
‚îî‚îÄ‚îÄ infrastructure       // Adattatori e implementazioni concrete
```

#### Strati Architetturali

- **Core**: Contiene la logica base indipendente dal dominio
  - `NeuralNetwork` - Implementazione matematica della rete neurale
  - `NeuralNetworkModel` - Interfaccia per modelli di rete neurale
  - `Normalizer<T,R>` - Interfaccia generica per normalizzazione dei dati

- **Domain**: Contiene le regole di business e interfacce specifiche del dominio
  - `PriceNormalizer` - Interfaccia per normalizzazione prezzi immobiliari
  - `FeatureNormalizer` - Interfaccia per normalizzazione caratteristiche immobiliari

- **Application**: Implementa i casi d'uso dell'applicazione
  - `RealEstateNeuralNetwork` - Sistema di valutazione immobiliare

- **Infrastructure**: Contiene implementazioni concrete delle interfacce
  - `NeuralNetworkAdapter` - Adapter per connettere la rete neurale all'interfaccia del modello
  - `DefaultPriceNormalizer` - Implementazione concreta per normalizzazione prezzi
  - `DefaultFeatureNormalizer` - Implementazione concreta per normalizzazione caratteristiche

#### Vantaggi dell'architettura

- **Indipendenza dai Framework** - Il core e il dominio non dipendono da librerie esterne
- **Testabilit√†** - Le interfacce permettono di testare i componenti in isolamento
- **Flessibilit√†** - Facile sostituire implementazioni (es. diversa strategia di normalizzazione)
- **Manutenibilit√†** - Ogni componente ha una responsabilit√† chiara e ben definita

### `NeuralNetwork.java`

Il cuore del progetto: implementazione da zero di una rete neurale feedforward con:

- **Inizializzazione dei pesi** - Valori casuali per i collegamenti tra neuroni
- **Feedforward** - Propagazione del segnale attraverso la rete
- **Backpropagation** - Calcolo dell'errore e aggiustamento dei pesi
- **Dropout** - Tecnica per prevenire l'overfitting
- **Funzioni di attivazione** - Implementazione manuale della funzione sigmoide

### `RealEstateNeuralNetwork.java`

Wrapper che applica la rete neurale al contesto immobiliare:

- **Normalizzazione** - Preprocessamento dei dati per la rete neurale
- **Pattern Adapter** - Integrazione modulare con la rete neurale
- **Valutazione** - Metriche per misurare l'accuratezza delle predizioni

### `RealEstateNeuralNetworkTest.java`

Test completi che verificano:

- **Convergenza** - Diminuzione dell'errore durante l'addestramento
- **Accuratezza** - Capacit√† predittiva su esempi noti
- **Generalizzazione** - Comportamento con dati mai visti
- **Robustezza** - Reazione a scenari limite

### `DefaultFeatureNormalizer.java`

Implementazione predefinita del normalizzatore di caratteristiche:

- **Normalizzazione** - Trasformazione delle caratteristiche degli immobili in un intervallo normalizzato
- **Denormalizzazione** - Riconversione delle caratteristiche normalizzate ai valori originali

### `DefaultPriceNormalizer.java`

Implementazione predefinita del normalizzatore di prezzi:

- **Normalizzazione** - Trasformazione dei prezzi degli immobili in un intervallo normalizzato
- **Denormalizzazione** - Riconversione dei prezzi normalizzati ai valori originali

### `FeatureNormalizer.java`

Interfaccia per la normalizzazione delle caratteristiche degli immobili:

- **Normalizzazione** - Definisce il metodo per normalizzare le caratteristiche
- **Denormalizzazione** - Definisce il metodo per denormalizzare le caratteristiche

### `PriceNormalizer.java`

Interfaccia per la normalizzazione dei prezzi degli immobili:

- **Normalizzazione** - Definisce il metodo per normalizzare i prezzi
- **Denormalizzazione** - Definisce il metodo per denormalizzare i prezzi

### `NeuralNetworkAdapter.java`

Adapter per la classe `NeuralNetwork` esistente:

- **Train** - Addestra la rete neurale con un esempio
- **Predict** - Esegue una predizione utilizzando la rete neurale

### `NeuralNetworkModel.java`

Interfaccia che definisce il comportamento di un modello di rete neurale:

- **Train** - Addestra il modello con un esempio
- **Predict** - Esegue una predizione utilizzando il modello

### `Normalizer.java`

Interfaccia generica per la normalizzazione dei dati:

- **Normalizzazione** - Definisce il metodo per normalizzare un valore
- **Denormalizzazione** - Definisce il metodo per denormalizzare un valore
-

## üõ†Ô∏è Requisiti Tecnici

- **Java 21+** - Utilizzo delle funzionalit√† pi√π recenti del linguaggio
- **Maven** - Gestione delle dipendenze e build automatizzata
- **SLF4J** - Logging strutturato per debug e tracciabilit√†
- **JUnit 5** - Framework per i test automatizzati

## ‚ö†Ô∏è Limitazioni

Essendo un progetto dimostrativo, presenta alcune limitazioni:

- **Performance** - Non ottimizzato per grandi dataset (usa calcoli na√Øf)
- **Funzioni di attivazione** - Implementa solo la funzione sigmoide
- **Architettura** - Supporta solo una topologia fissa con un singolo strato nascosto
- **Batch processing** - Non implementa il mini-batch gradient descent

## ü§ù Come Contribuire

Questo √® un progetto didattico, ma i contributi sono benvenuti:

1. Fork del repository
2. Crea un branch (`git checkout -b feature/miglioramento-xyz`)
3. Commit delle modifiche (`git commit -m 'Aggiunto xyz'`)
4. Push al branch (`git push origin feature/miglioramento-xyz`)
5. Apri una Pull Request

## üìù Licenza

Questo progetto √® rilasciato sotto licenza MIT. Consulta il file `LICENSE` per maggiori dettagli.

## üìû Contatti

Gianluca Bove - [@gbove73](https://github.com/gbove73)

Repository: [github.com/gbove73/neural-network](https://github.com/gbove73/neural-network)

---

*Questo progetto ha scopo puramente dimostrativo ed educativo. L'implementazione manuale di una rete neurale √® un esercizio didattico: in ambito produttivo si consiglia di utilizzare librerie mature e ottimizzate come TensorFlow, PyTorch o DeepLearning4J.*